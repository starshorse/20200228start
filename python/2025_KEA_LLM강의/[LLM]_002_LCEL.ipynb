{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7cd25bfb",
      "metadata": {},
      "source": [
        "# LangChain LCEL\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2217fa83",
      "metadata": {},
      "source": [
        "## LCEL(LangChain Expression Language) \n",
        "\n",
        "* 선언적 체이닝: 여러 컴포넌트를 `|` 연산자로 연결하여 파이프라인을 구성할 수 있으며, 실행은 순차적으로 이루어집니다.\n",
        "\n",
        "* 재사용성: LCEL로 정의된 체인은 독립적인 컴포넌트로 취급되어 다른 체인에서 재사용이 가능합니다.\n",
        "\n",
        "* 유연한 입출력 처리: `.invoke()`, `.batch()`, `.stream()`, `.astream()` 등 다양한 실행 방식을 지원하여 동기/비동기 처리가 가능합니다.\n",
        "\n",
        "* 배치 처리 최적화: 여러 입력을 동시에 처리할 때 자동으로 최적화를 수행하여 효율성을 높입니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bfd9328",
      "metadata": {
        "id": "8bfd9328"
      },
      "source": [
        "### 1. 환경 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15ac3ddb",
      "metadata": {
        "id": "15ac3ddb"
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "# Langsmith tracing 여부를 확인 (true: langsmith 추척 활성화, false: langsmith 추척 비활성화)\n",
        "import os\n",
        "print(os.getenv('LANGCHAIN_TRACING_V2'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "129b8eee",
      "metadata": {
        "id": "129b8eee"
      },
      "source": [
        "### 2. LCEL  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68074eb8",
      "metadata": {
        "id": "68074eb8"
      },
      "source": [
        "#### 1) **Prompt + LLM**\n",
        "\n",
        "* 기본 구조: `Prompt | LLM` 형태로, 파이프(|) 연산자를 사용해 프롬프트와 LLM을 순차적으로 연결합니다.\n",
        "\n",
        "* 데이터 흐름: 사용자 입력이 Prompt 템플릿을 통해 처리된 후, LLM에 전달되어 최종 응답이 생성됩니다.\n",
        "\n",
        "* 실행 순서: 파이프라인은 왼쪽에서 오른쪽으로 순차적으로 실행되며, 각 컴포넌트의 출력이 다음 컴포넌트의 입력으로 전달됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3722db67",
      "metadata": {
        "id": "3722db67"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# LLM model\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-4o-mini\", \n",
        "    temperature=0.3, \n",
        "    max_tokens=100,\n",
        "    )\n",
        "\n",
        "# 모델에 프롬프트를 입력\n",
        "response = llm.invoke(\"탄소의 원자 번호는 무엇인가요?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e87eef4",
      "metadata": {
        "id": "9e87eef4"
      },
      "outputs": [],
      "source": [
        "# 응답 객체 확인\n",
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47ce51f7",
      "metadata": {
        "id": "47ce51f7"
      },
      "outputs": [],
      "source": [
        "# 응답 객체의 텍스트를 확인\n",
        "response.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "552cd7af",
      "metadata": {
        "id": "552cd7af"
      },
      "outputs": [],
      "source": [
        "# 응답 객체의 메타데이터를 확인\n",
        "response.response_metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa0f1db8",
      "metadata": {},
      "source": [
        "**[템플릿 예시]**\n",
        "\n",
        "```mermaid\n",
        "%%{init: {'flowchart': {'nodeSpacing': 25, 'rankSpacing': 20, 'fontSize': 11}}}%%\n",
        "flowchart LR\n",
        "    subgraph \"템플릿 변수\"\n",
        "        T[topic]\n",
        "        Q[question]\n",
        "    end\n",
        "    \n",
        "    subgraph \"프롬프트 템플릿\"\n",
        "        R1[\"역할 정의:<br>{topic} 전문가\"]\n",
        "        R2[\"질문 처리:<br>{question}\"]\n",
        "    end\n",
        "    \n",
        "    subgraph \"결과 구조\"\n",
        "        F[\"최종 프롬프트\"]\n",
        "        O[\"출력 형식:<br>전문가 답변\"]\n",
        "    end\n",
        "    \n",
        "    T --> R1\n",
        "    Q --> R2\n",
        "    R1 --> F\n",
        "    R2 --> F\n",
        "    F --> O\n",
        "    \n",
        "    style T fill:#bbf,stroke:#333,stroke-width:2px\n",
        "    style Q fill:#bbf,stroke:#333,stroke-width:2px\n",
        "    style F fill:#dfd,stroke:#333,stroke-width:2px\n",
        "    style O fill:#fdd,stroke:#333,stroke-width:2px\n",
        "```\n",
        "* Markdown Preview Mermaid Support 확장프로그램 설치 (VSCode)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0113cf90",
      "metadata": {
        "id": "0113cf90"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "# 템플릿 문자열 정의\n",
        "template = \"\"\"\n",
        "당신은 {topic} 분야의 전문가입니다. {topic}에 관한 다음 질문에 답변해주세요.\n",
        "질문: {question}\n",
        "답변: \"\"\"\n",
        "\n",
        "# PromptTemplate 객체 생성\n",
        "prompt = PromptTemplate.from_template(template)\n",
        "\n",
        "# 템플릿 사용 예시\n",
        "formatted_prompt = prompt.format(\n",
        "    topic=\"인공지능\",\n",
        "    question=\"딥러닝과 머신러닝의 주요 차이점은 무엇인가요?\"\n",
        ")\n",
        "\n",
        "print(\"템플릿 변수:\")\n",
        "print(f\"- 필수 변수: {prompt.input_variables}\")\n",
        "print(\"\\n생성된 프롬프트:\")\n",
        "print(formatted_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25b245d7",
      "metadata": {
        "id": "25b245d7"
      },
      "outputs": [],
      "source": [
        "# prompt 객체의 템플릿을 확인\n",
        "print(prompt.template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c801f727",
      "metadata": {
        "id": "c801f727"
      },
      "outputs": [],
      "source": [
        "# chain을 구성\n",
        "chain = prompt | llm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b53e9def",
      "metadata": {
        "id": "b53e9def"
      },
      "outputs": [],
      "source": [
        "# chain 객체 확인\n",
        "chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d4f916f",
      "metadata": {
        "id": "6d4f916f"
      },
      "outputs": [],
      "source": [
        "# chain 객체의 입력 스키마를 확인\n",
        "chain.input_schema.model_json_schema() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6015e000",
      "metadata": {
        "id": "6015e000"
      },
      "outputs": [],
      "source": [
        "# chain 실행\n",
        "response = chain.invoke( \n",
        "    {\n",
        "        \"topic\": \"화학(Chemistry)\", \n",
        "        \"question\": \"탄소의 원자 번호는 무엇인가요?\"\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa75f9ee",
      "metadata": {
        "id": "fa75f9ee"
      },
      "outputs": [],
      "source": [
        "# 응답 객체를 출력\n",
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb0a3843",
      "metadata": {
        "id": "fb0a3843"
      },
      "outputs": [],
      "source": [
        "# 응답 객체의 텍스트를 출력\n",
        "response.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6c5710c",
      "metadata": {
        "id": "c6c5710c"
      },
      "outputs": [],
      "source": [
        "# 응답 객체의 메타데이터를 출력\n",
        "response.response_metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "983d4157",
      "metadata": {
        "id": "983d4157"
      },
      "source": [
        "#### **2) Prompt + LLM + Output Parser**\n",
        "\n",
        "* 데이터 파이프라인: `Prompt | LLM | OutputParser` 형태로 구성되어 LLM의 출력을 구조화된 형식으로 변환합니다.\n",
        "\n",
        "* Parser 종류: JSON, XML 등 다양한 형식의 파서를 지원하여 LLM 출력을 원하는 데이터 구조로 변환할 수 있습니다.\n",
        "\n",
        "* 유효성 검증: Parser가 출력 형식을 검증하여 잘못된 형식의 응답을 필터링하고 안정적인 데이터 처리를 보장합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e6b7607",
      "metadata": {
        "id": "7e6b7607"
      },
      "outputs": [],
      "source": [
        "### 문자열 출력 파서 \n",
        "\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# 출력 파서를 생성\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "# 출력 파서를 실행\n",
        "output_parser.invoke(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "158608d9",
      "metadata": {
        "id": "158608d9"
      },
      "outputs": [],
      "source": [
        "# 출력 파서를 chain에 추가\n",
        "chain = prompt | llm | output_parser\n",
        "\n",
        "# chain을 실행\n",
        "response = chain.invoke(\n",
        "    {\n",
        "        \"topic\": \"화학(Chemistry)\", \n",
        "        \"question\": \"탄소의 원자 번호는 무엇인가요?\"\n",
        "    }\n",
        ")\n",
        "\n",
        "# 응답 객체를 출력\n",
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e95ba99",
      "metadata": {
        "id": "1e95ba99"
      },
      "outputs": [],
      "source": [
        "# input_schema (chain)\n",
        "chain.input_schema.model_json_schema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba0d6997",
      "metadata": {
        "id": "ba0d6997"
      },
      "outputs": [],
      "source": [
        "# input_schema (prompt)\n",
        "prompt.input_schema.model_json_schema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7abd42cd",
      "metadata": {
        "id": "7abd42cd"
      },
      "outputs": [],
      "source": [
        "# input_schema (model)\n",
        "llm.input_schema.model_json_schema()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4456bde9",
      "metadata": {
        "id": "4456bde9"
      },
      "source": [
        "### 3. Runnable\n",
        "\n",
        "* 실행 인터페이스: 모든 LangChain 컴포넌트는 Runnable 인터페이스를 구현하여 일관된 방식으로 실행됩니다.\n",
        "\n",
        "* 실행 메서드: `.invoke()`, `.batch()`, `.stream()`, `.astream()` 등 다양한 실행 방식을 제공합니다.\n",
        "\n",
        "* 호환성: 모든 Runnable 컴포넌트는 파이프(|) 연산자를 통해 연결 가능하며, 재사용이 용이합니다.\n",
        "\n",
        "* Runnable의 주요 유형:\n",
        "\n",
        "    * `RunnableSequence`: 여러 Runnable을 순차적으로 실행\n",
        "    * `RunnablePassthrough`: 입력을 그대로 다음 단계로 전달    \n",
        "    * `RunnableParallel`: 여러 Runnable을 병렬로 실행\n",
        "    * `RunnableLambda`: 파이썬 함수를 Runnable로 래핑하여 체인에서 사용"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "022d0cfd",
      "metadata": {},
      "source": [
        "#### 1) **RunnableSequence**\n",
        "- 정의: 각 구성요소의 출력이 다음 구성요소의 입력으로 전달되는 Runnable 객체들의 시퀀스 체인\n",
        "- 출력: 각 단계를 순차적으로 실행한 최종 결과값 반환\n",
        "- 주요 특징:\n",
        "    - `|` 연산자로 간단히 연결 가능\n",
        "    - 동기/비동기 실행 지원\n",
        "    - 배치/스트리밍 처리 지원\n",
        "\n",
        "- 용도:\n",
        "  - LLM 체인 구성\n",
        "  - 데이터 전처리/후처리 파이프라인 \n",
        "  - 멀티스텝 작업 자동화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac7c9cd0",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnableSequence\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "\n",
        "# 컴포넌트 정의\n",
        "prompt = PromptTemplate.from_template(\"'{text}'를 영어로 번역해주세요. 번역된 문장만을 출력해주세요.\")\n",
        "translator = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.3, max_tokens=100)\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "# RunnableSequence 생성 - 함수 사용 \n",
        "translation_chain = RunnableSequence(\n",
        "    first=prompt,\n",
        "    middle=[translator],   # 리스트로 전달하는 점에 주의\n",
        "    last=output_parser\n",
        ")\n",
        "\n",
        "# RunnableSequence 생성 - 연산자 사용\n",
        "# translation_chain = prompt | translator | output_parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae5ff8cd",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 동기 실행\n",
        "result = translation_chain.invoke({\"text\": \"안녕하세요\"})\n",
        "print(result)  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04a93db3",
      "metadata": {},
      "source": [
        "**[비동기 처리의 주요 이점]**\n",
        "\n",
        "* 응답성: I/O 작업 중 다른 작업 수행이 가능하여 시스템 전체 응답성 향상\n",
        "\n",
        "* 확장성: 여러 요청을 동시에 처리할 수 있어 처리량 증가\n",
        "\n",
        "* 리소스 활용: CPU와 메모리를 효율적으로 활용하여 성능 최적화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d2ad50f",
      "metadata": {},
      "outputs": [],
      "source": [
        "import asyncio\n",
        "import nest_asyncio\n",
        "\n",
        "# Jupyter에서 비동기 실행을 위한 설정\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# 비동기 실행 함수를 정의\n",
        "async def run():\n",
        "    result = await translation_chain.ainvoke({\"text\": \"감사합니다\"})\n",
        "    print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01afbeb7",
      "metadata": {},
      "outputs": [],
      "source": [
        "#  비동기 실행 함수를 호출\n",
        "await run()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fb7e8bf",
      "metadata": {},
      "source": [
        "#### 2) **RunnableParallel**\n",
        "\n",
        "* 실행 가능한 객체들을 딕셔너리 형태로 구성하여 병렬 처리를 가능하게 하는 컴포넌트로, 모든 값들이 동시에 실행되어 효율적인 처리가 가능합니다\n",
        "\n",
        "* 입력값은 모든 병렬 실행 컴포넌트에 동일하게 전달되며, 각 실행 결과는 원래 키와 매핑된 새로운 딕셔너리로 반환됩니다\n",
        "\n",
        "* 데이터 변환과 파이프라인 구성에 유용하며, 특히 한 Runnable의 출력을 다음 단계의 입력 형식에 맞게 조정하는 데 효과적입니다"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "625baaa0",
      "metadata": {},
      "source": [
        "`(1) 질문 분석 체인`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f19926e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 질문과 관련된 분야를 찾는 프롬프트\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# 출력 파서 정의\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "# 질문 템플릿 정의\n",
        "question_template = \"\"\"\n",
        "다음 카테고리 중 하나로 입력을 분류하세요:\n",
        "- 화학(Chemistry)\n",
        "- 물리(Physics)\n",
        "- 생물(Biology)\n",
        "\n",
        "# 예시:\n",
        "입력: 사람의 염색체는 모두 몇개가 있나요?\n",
        "답변: 생물(Biology)\n",
        "\n",
        "입력: {question}\n",
        "답변: \"\"\"\n",
        "\n",
        "# 프롬프트 생성\n",
        "question_prompt = ChatPromptTemplate.from_template(question_template)\n",
        "\n",
        "# 체인 구성\n",
        "question_chain = question_prompt | llm | output_parser\n",
        "\n",
        "# 체인 실행\n",
        "result = question_chain.invoke({\"question\": \"탄소의 원자 번호는 무엇인가요?\"})\n",
        "print(f\"분류 결과: {result}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a59c649",
      "metadata": {},
      "source": [
        "```mermaid\n",
        "flowchart LR\n",
        "    Q[사용자 질문] --> T[템플릿 적용]\n",
        "\n",
        "    subgraph 프롬프트 처리\n",
        "        T --> P[프롬프트 생성]\n",
        "        P --> LLM[LLM 모델]\n",
        "    end\n",
        "    \n",
        "    subgraph 분류 프로세스\n",
        "        LLM --> D{주제 분류}\n",
        "        D -->|화학 관련| C[화학]\n",
        "        D -->|물리 관련| PH[물리]\n",
        "        D -->|생물 관련| B[생물]\n",
        "    end\n",
        "    \n",
        "    C --> R[결과 반환]\n",
        "    PH --> R\n",
        "    B --> R\n",
        "    \n",
        "    style Q fill:#f9f,stroke:#333,stroke-width:2px\n",
        "    style D fill:#bbf,stroke:#333,stroke-width:2px\n",
        "    style C fill:#dfd,stroke:#333,stroke-width:2px\n",
        "    style PH fill:#dfd,stroke:#333,stroke-width:2px\n",
        "    style B fill:#dfd,stroke:#333,stroke-width:2px\n",
        "    style R fill:#fdd,stroke:#333,stroke-width:2px\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9afa45a8",
      "metadata": {},
      "source": [
        "`(2) 언어 감지 체인`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5ce2883",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 질문에 사용된 언어를 구분하는 프롬프트\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# 출력 파서 정의\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "# 언어 분류 템플릿 정의\n",
        "language_template = \"\"\"\n",
        "입력된 텍스트의 언어를 다음 카테고리 중 하나로 분류하세요:\n",
        "- 영어(English)\n",
        "- 한국어(Korean)\n",
        "- 기타(Others)\n",
        "\n",
        "# 예시:\n",
        "입력: How many protons are in a carbon atom?\n",
        "답변: English\n",
        "\n",
        "입력: {question}\n",
        "답변: \"\"\"\n",
        "\n",
        "# 프롬프트 생성\n",
        "language_prompt = ChatPromptTemplate.from_template(language_template)\n",
        "\n",
        "# 체인 구성\n",
        "language_chain = language_prompt | llm | output_parser\n",
        "\n",
        "# 체인 실행 예시\n",
        "examples = [\n",
        "    \"What is the atomic number of carbon?\",\n",
        "    \"탄소의 원자 번호는 무엇인가요?\",\n",
        "    \"¿Cuál es el número atómico del carbono?\"\n",
        "]\n",
        "\n",
        "for example in examples:\n",
        "    result = language_chain.invoke({\"question\": example})\n",
        "    print(f\"입력: {example}\")\n",
        "    print(f\"분류 결과: {result}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "625423de",
      "metadata": {},
      "source": [
        "```mermaid\n",
        "flowchart LR\n",
        "    Q[\"입력 텍스트\"] --> P[\"프롬프트 생성\"]\n",
        "    \n",
        "    subgraph \"언어 분석\"\n",
        "        P --> LLM[\"LLM 모델\"]\n",
        "    end\n",
        "    \n",
        "    subgraph \"언어 분류\"\n",
        "        LLM --> D{\"언어 판별\"}\n",
        "        D -->|\"영어 텍스트\"| E[\"English\"]\n",
        "        D -->|\"한글 텍스트\"| K[\"Korean\"]\n",
        "        D -->|\"기타 언어\"| O[\"Others\"]\n",
        "    end\n",
        "    \n",
        "    E --> R[\"결과 반환\"]\n",
        "    K --> R\n",
        "    O --> R\n",
        "    \n",
        "    style Q fill:#f9f,stroke:#333,stroke-width:2px\n",
        "    style D fill:#bbf,stroke:#333,stroke-width:2px\n",
        "    style E fill:#dfd,stroke:#333,stroke-width:2px\n",
        "    style K fill:#dfd,stroke:#333,stroke-width:2px\n",
        "    style O fill:#dfd,stroke:#333,stroke-width:2px\n",
        "    style R fill:#fdd,stroke:#333,stroke-width:2px\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c273a56e",
      "metadata": {},
      "source": [
        "`(3) RunnableParallel을 사용한 병렬 실행 체인`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf0b47c9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 질문과 관련된 분야를 찾아서 질문에 대한 답변을 생성하는 프롬프트\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnableParallel\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from operator import itemgetter\n",
        "\n",
        "# 답변 템플릿 정의\n",
        "answer_template = \"\"\"\n",
        "당신은 {topic} 분야의 전문가입니다. {topic}에 관한 질문에 {language}로 답변해주세요.\n",
        "질문: {question}\n",
        "답변: \"\"\"\n",
        "\n",
        "# 프롬프트 및 체인 구성\n",
        "answer_prompt = ChatPromptTemplate.from_template(answer_template)\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "# 병렬 처리 체인 구성\n",
        "answer_chain = RunnableParallel({\n",
        "    \"topic\": question_chain,            # 주제 분류 체인\n",
        "    \"language\": language_chain,         # 언어 감지 체인\n",
        "    \"question\": itemgetter(\"question\")  # 원본 질문 추출\n",
        "}) | answer_prompt | llm | output_parser\n",
        "\n",
        "# 체인 실행 예시\n",
        "result = answer_chain.invoke({\n",
        "    \"question\": \"탄소의 원자 번호는 무엇인가요?\"\n",
        "})\n",
        "\n",
        "print(\"처리 결과:\")\n",
        "print(f\"답변: {result}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53fe248d",
      "metadata": {},
      "source": [
        "```mermaid\n",
        "flowchart TD\n",
        "    Q[\"입력 질문\"] --> RP[\"RunnableParallel 처리\"]\n",
        "    \n",
        "    subgraph \"병렬 처리\"\n",
        "        direction TB\n",
        "        RP --> TC[\"주제 분류 체인\"]\n",
        "        RP --> LC[\"언어 감지 체인\"]\n",
        "        RP --> QE[\"질문 추출\"]\n",
        "        \n",
        "        TC --> T[\"분야 판별<br>(chemistry/physics/biology)\"]\n",
        "        LC --> L[\"언어 판별<br>(Korean/English/Others)\"]\n",
        "        QE --> QO[\"원본 질문\"]\n",
        "    end\n",
        "    \n",
        "    T --> AP[\"답변 프롬프트 생성\"]\n",
        "    L --> AP\n",
        "    QO --> AP\n",
        "    \n",
        "    subgraph \"답변 생성\"\n",
        "        AP --> LM[\"LLM 모델\"]\n",
        "        LM --> OP[\"출력 파서\"]\n",
        "    end\n",
        "    \n",
        "    OP --> R[\"최종 답변\"]\n",
        "    \n",
        "    style Q fill:#f9f,stroke:#333,stroke-width:2px\n",
        "    style RP fill:#bbf,stroke:#333,stroke-width:2px\n",
        "    style T fill:#dfd,stroke:#333,stroke-width:2px\n",
        "    style L fill:#dfd,stroke:#333,stroke-width:2px\n",
        "    style QO fill:#dfd,stroke:#333,stroke-width:2px\n",
        "    style R fill:#fdd,stroke:#333,stroke-width:2px\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70e0e431",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 다른 예시 질문으로 테스트\n",
        "test_questions = [\n",
        "    # 화학 관련 질문\n",
        "    \"물의 분자식은 무엇인가요?\",\n",
        "    \n",
        "    # 물리 관련 질문\n",
        "    \"What is Newton's first law of motion?\",\n",
        "    \n",
        "    # 생물 관련 질문\n",
        "    \"세포의 기본 구조를 설명해주세요.\"\n",
        "]\n",
        "\n",
        "for question in test_questions:\n",
        "    print(f\"\\n질문: {question}\")\n",
        "    result = answer_chain.invoke({\"question\": question})\n",
        "    print(f\"답변: {result}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89ddb27f",
      "metadata": {},
      "source": [
        "#### 3) **RunnablePassthrough**\n",
        "\n",
        "* 입력값을 수정 없이 그대로 통과시키는 간단한 Runnable 컴포넌트로, 데이터 파이프라인에서 원본 입력을 보존하는 데 활용됩니다\n",
        "\n",
        "* RunnableParallel과 조합하여 사용될 때 특히 유용하며, 입력 데이터를 병렬 실행 맵의 새로운 키로 전달하는 기능을 제공합니다\n",
        "\n",
        "* 데이터 흐름을 투명하게 만들어 디버깅과 파이프라인 구성을 단순화하는 장점이 있습니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11de1469",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "import re\n",
        "\n",
        "runnable = RunnableParallel(\n",
        "    passed=RunnablePassthrough(),\n",
        "    modified=lambda x: int(re.search(r'\\d+', x[\"query\"]).group()),\n",
        ")\n",
        "\n",
        "runnable.invoke({\"query\": '탄소의 원자 번호는 6입니다.'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "346a12dc",
      "metadata": {},
      "outputs": [],
      "source": [
        "runnable = RunnableParallel(\n",
        "    passed=RunnablePassthrough(),\n",
        "    modified=lambda x: int(re.search(r'\\d+', x).group()),\n",
        ")\n",
        "\n",
        "runnable.invoke('탄소의 원자 번호는 6입니다.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e888c65",
      "metadata": {
        "id": "2e888c65"
      },
      "source": [
        "`(4) RunnableLambda`\n",
        "\n",
        "* 일반 함수를 Runnable 객체로 변환하여 체인에서 사용할 수 있게 해주는 래퍼(wrapper) 컴포넌트입니다\n",
        "\n",
        "* 데이터 전처리, 후처리, 변환 등 커스텀 로직을 체인에 쉽게 통합할 수 있게 해줍니다\n",
        "\n",
        "* 다른 Runnable 컴포넌트들과 마찬가지로 파이프라인 연산자(`|`)를 통해 연결하여 복잡한 처리 흐름을 구성할 수 있습니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7f8d92f",
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
        "\n",
        "# 텍스트에서 숫자를 추출하는 함수\n",
        "def extract_number(query):\n",
        "    return int(re.search(r'\\d+', query).group())\n",
        "\n",
        "# RunnablePassthrough로 입력을 그대로 전달하고, RunnableLambda로 숫자 추출 함수 실행\n",
        "runnable = RunnablePassthrough() | RunnableLambda(extract_number)\n",
        "\n",
        "# 입력 텍스트에서 6을 추출\n",
        "result = runnable.invoke('탄소의 원자 번호는 6입니다.')\n",
        "print(result)  # 출력: 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6704894c",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.schema.runnable import RunnableLambda\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "# 데이터 전처리 함수 정의\n",
        "def preprocess_text(text: str) -> str:\n",
        "    \"\"\" 입력 텍스트를 소문자로 변환하고 양쪽 공백을 제거합니다. \"\"\"\n",
        "    return text.strip().lower()\n",
        "\n",
        "# 후처리 함수 정의\n",
        "def postprocess_response(response: str) -> dict:\n",
        "    \"\"\" 응답 텍스트를 대문자로 변환하고 길이를 계산합니다. \"\"\"\n",
        "    response_text = response.content\n",
        "    return {\n",
        "        \"processed_response\": response_text.upper(),\n",
        "        \"length\": len(response_text)\n",
        "    }\n",
        "\n",
        "# 프롬프트 템플릿 생성\n",
        "prompt = ChatPromptTemplate.from_template(\"다음 주제에 대해 영어 한 문장으로 설명해주세요: {topic}\")\n",
        "\n",
        "# 처리 파이프라인 구성\n",
        "chain = (\n",
        "    RunnableLambda(preprocess_text) |  # 입력 전처리\n",
        "    prompt |                           # 프롬프트 포맷팅\n",
        "    llm |                              # LLM 추론\n",
        "    RunnableLambda(postprocess_response)  # 출력 후처리\n",
        ")\n",
        "\n",
        "# 체인 실행\n",
        "result = chain.invoke(\"인공지능\")\n",
        "print(f\"처리된 응답: {result['processed_response']}\")\n",
        "print(f\"응답 길이: {result['length']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "367d46b8",
      "metadata": {},
      "source": [
        "# [실습]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd5b260a",
      "metadata": {},
      "source": [
        "- **다음과 같은 요구사항을 LCEL로 구현합니다**\n",
        "   1. 사용자 입력을 받아 요약하기\n",
        "   2. 요약된 내용을 기반으로 감정 분석하기 (긍정, 부정, 중립)\n",
        "   3. 요약된 문장과 감정 분석 결과를 출력하기 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43e424f7",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# 프롬프트 템플릿 정의\n",
        "summarize_prompt = None\n",
        "\n",
        "sentiment_prompt = None\n",
        "\n",
        "# 문자열 출력 파서\n",
        "output_parser = None\n",
        "\n",
        "# 체인 구성\n",
        "model = None\n",
        "\n",
        "# 요약 체인\n",
        "summarize_chain = None\n",
        "\n",
        "# 감정 분석 체인\n",
        "sentiment_chain = None\n",
        "\n",
        "# 전체 체인\n",
        "chain = (\n",
        "    summarize_chain \n",
        "    | None(\n",
        "        summary=lambda x: None,\n",
        "        sentiment=lambda x: sentiment_chain.invoke({\"summary\": x.content}),\n",
        "    )\n",
        ")\n",
        "\n",
        "# 사용 예시\n",
        "text = \"오늘 시험에서 만점을 받았다. 정말 기쁘고 노력한 보람이 있었다!\"\n",
        "result = chain.None({\"text\": text})\n",
        "print(f\"요약: {result['summary']}\")\n",
        "print(f\"감정 분석: {result['sentiment']}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "modu-01-YKUqNpBc-py3.12",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
