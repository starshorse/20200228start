{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49a4d481",
   "metadata": {},
   "source": [
    "# LangChain을 활용한 뉴스 요약 및 키워드 추출\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb2476b",
   "metadata": {},
   "source": [
    "## 환경 설정 및 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363dfcd6",
   "metadata": {},
   "source": [
    "`(1) Env 환경변수`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27bfdacd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e76942",
   "metadata": {},
   "source": [
    "`(2) 기본 라이브러리`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2192c8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import re\n",
    "import json\n",
    "\n",
    "from textwrap import dedent\n",
    "from pprint import pprint\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4d32cb",
   "metadata": {},
   "source": [
    "`(3) 뉴스 데이터 로드`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29ad8359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로드된 문서 수: 69\n"
     ]
    }
   ],
   "source": [
    "# pickle 파일에서 데이터 로드\n",
    "import pickle\n",
    "\n",
    "with open(\"processed_news_articles.pkl\", \"rb\") as f:\n",
    "    loaded_docs = pickle.load(f)\n",
    "    print(f\"로드된 문서 수: {len(loaded_docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36736278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'https://n.news.naver.com/mnews/article/018/0005968393?sid=105',\n",
       " 'media_outlet': '이데일리',\n",
       " 'reporter': '김현아',\n",
       " 'content': '인공지능(AI) 기업 크라우드웍스가 중국 기업 딥시크와 계약을 체결하고 딥시크의 공식적인 한국어 특화 모델을 개발한다는 보도에 대해 반박했다. 크라우드웍스는 해당 보도 내용이 사실이 아니며, 딥시크와 어떠한 형태로도 직접적인 협업 관계가 없음을 명확히 밝혔다. 크라우드웍스는 일본 법인인 CWJ(크라우드웍스 재팬)를 통해 일본의 협력사 Aicho(아이초)와 협업하고 있으며, Aicho는 최근 딥시크 R1 모델을 기반으로 일본어 특화 모델을 개발한 바 있으며, 크라우드웍스는 이를 바탕으로 한국어 특화 모델을 개발할 예정이다. 이는 딥시크와의 계약이 아니며, Aicho의 일본어 모델을 기반으로 한 한국어 특화 모델 개발에 해당한다고 설명했다. 또한, 크라우드웍스는 딥시크의 개인정보 유출 문제가 B2C 모델에서 발생한 사안이며, 자신들이 Aicho와 공동 개발 중인 한국어 모델은 일반 소비자 대상이 아닌 B2B 모델에 해당한다고 밝혔다. 이 한국어 특화 모델은 주로 해외 시장을 타겟으로 하며, 금융, 공공, 국방 등 보안이 민감한 산업 분야에는 공급될 계획이 없다고 강조했다. 기업의 특별한 니즈가 있을 경우 온프레미스 환경에서의 활용을 검토할 수 있으며, 이는 물리적으로 제한된 네트워크 환경 내에서만 운영돼 외부 네트워크와의 통신 여부를 철저히 검증할 수 있다고 설명했다. 크라우드웍스는 최근 K-콘텐츠와 K-커머스의 글로벌 확산에 따라 한국어에 특화된 AI 모델에 대한 수요가 급증하고 있음을 언급하며, 해외 시장 진출을 목표로 한국어 특화 모델 개발을 추진하고 있다고 밝혔다.'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_docs[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf95809",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **LLM을 활용한 텍스트 분석**\n",
    "\n",
    "- **LangChain**: LLM 기반 애플리케이션 개발을 위한 프레임워크\n",
    "- **텍스트 요약 (Summarization)**: 긴 문서를 간결하고 의미 있는 형태로 변환\n",
    "- **키워드 추출 (Extraction)**: 문서에서 핵심 용어와 개념을 자동으로 식별\n",
    "- **평가 (Evaluation)**: 생성된 결과의 품질을 정량적/정성적으로 측정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ff6219",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 1. **텍스트 요약 (Summarization)**\n",
    "\n",
    "- **텍스트 요약의 목적**\n",
    "    - 긴 문서의 **핵심 내용만 추출**하여 읽기 시간 단축\n",
    "    - 정보의 **본질적 의미는 유지**하면서 길이 축소\n",
    "    - 대량의 문서를 빠르게 **스캔하고 분류**하는 데 활용\n",
    "\n",
    "- **요약의 유형**\n",
    "    - **추출적 요약 (Extractive)**: 원문에서 중요한 문장을 그대로 선택\n",
    "    - **생성적 요약 (Abstractive)**: 원문을 이해하고 새로운 문장으로 재작성 ⭐ (LLM 방식)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6973a17e",
   "metadata": {},
   "source": [
    "##### **1) 텍스트 요약 체인**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "097a2257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "요약 결과: LangChain은 LLM 기반 애플리케이션 개발 프레임워크로, 데이터 연결, 프롬프트 관리, 체인 구성, 메모리 기능을 지원합니다.\n",
      "요약 길이: 74\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# LLM 초기화\n",
    "llm = init_chat_model(\"openai:gpt-4.1-mini\", temperature=0)\n",
    "\n",
    "# 요약 프롬프트 템플릿 정의\n",
    "summarization_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"다음 텍스트를 간결하게 요약하세요. 핵심 내용만 포함하고 중요한 정보는 유지하세요. (공백 포함 100글자 이내로 요약)\"),\n",
    "    (\"human\", \"{text}\")\n",
    "])\n",
    "\n",
    "# 요약 체인 생성\n",
    "summarization_chain = summarization_prompt | llm | StrOutputParser()\n",
    "\n",
    "# 예시 사용\n",
    "text = \"\"\"\n",
    "LangChain은 대규모 언어 모델(LLM)을 활용한 애플리케이션 개발을 위한 프레임워크입니다. \n",
    "이 프레임워크는 LLM을 외부 데이터 소스와 연결하고, 다양한 모듈을 제공하여 \n",
    "더 강력한 애플리케이션을 만들 수 있게 도와줍니다. \n",
    "LangChain은 프롬프트 관리, 체인 구성, 에이전트 개발 등 다양한 기능을 제공합니다. \n",
    "또한 메모리 기능을 통해 대화 맥락을 유지하고, 다양한 도구와의 통합을 지원합니다.\n",
    "\"\"\"\n",
    "\n",
    "summary = summarization_chain.invoke({\"text\": text})\n",
    "print(\"요약 결과:\", summary)\n",
    "print(\"요약 길이:\", len(summary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175240f4",
   "metadata": {},
   "source": [
    "##### **2) 텍스트 요약 평가**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d860038a",
   "metadata": {},
   "source": [
    "`(1) 요약 길이`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99525b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "답변: LangChain은 LLM 기반 애플리케이션 개발 프레임워크로, 데이터 연결, 프롬프트 관리, 체인 구성, 메모리 기능을 지원합니다.\n",
      "길이 평가 결과: {'score': False, 'length': 74}\n"
     ]
    }
   ],
   "source": [
    "# 길이 평가도구 정의 \n",
    "def evaluate_string_length(text, min_length=80, max_length=120):\n",
    "    length = len(text)\n",
    "    return {\n",
    "        \"score\": min_length <= length <= max_length,\n",
    "        \"length\": length\n",
    "    }\n",
    "\n",
    "# 길이 평가 수행\n",
    "print(f\"답변: {summary}\")\n",
    "\n",
    "# 길이 평가\n",
    "result = evaluate_string_length(summary)\n",
    "print(f\"길이 평가 결과: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12029560",
   "metadata": {},
   "source": [
    "`(2) ROUGE`\n",
    "\n",
    "- **ROUGE(Recall-Oriented Understudy for Gisting Evaluation)**\n",
    "\n",
    "    - 생성된 요약문의 품질을 평가\n",
    "\n",
    "- ROUGE-1:\n",
    "    - 참조 문서와 생성된 요약문 사이의 단일 단어(unigram) 중복을 측정 \n",
    "    - 예시: \"고양이가 잠을 잡니다\"와 \"고양이는 낮잠을 잡니다\" 비교\n",
    "        - 참조: [\"고양이\", \"가\", \"잠\", \"을\", \"잡니다\"]\n",
    "        - 생성: [\"고양이\", \"는\", \"낮잠\", \"을\", \"잡니다\"]\n",
    "        - 일치: [\"고양이\", \"을\", \"잡니다\"]\n",
    "        - Precision = 3/5 = 0.6\n",
    "        - Recall = 3/5 = 0.6\n",
    "        - F1 = 0.6\n",
    "\n",
    "- ROUGE-2:\n",
    "    - 연속된 두 단어(bigram) 시퀀스의 중복을 평가\n",
    "    - 예시: \"고양이가 잠을 잡니다\"와 \"고양이는 낮잠을 잡니다\" 비교\n",
    "        - 참조: [\"고양이 가\", \"가 잠\", \"잠 을\", \"을 잡니다\"]\n",
    "        - 생성: [\"고양이 는\", \"는 낮잠\", \"낮잠 을\", \"을 잡니다\"]\n",
    "        - 일치: [\"을 잡니다\"]\n",
    "        - Precision = 1/4 = 0.25\n",
    "        - Recall = 1/4 = 0.25\n",
    "        - F1 = 0.25\n",
    "\n",
    "- ROUGE-L:\n",
    "    - 최장 공통 부분수열(LCS)을 기반으로 텍스트의 유사도를 측정\n",
    "    - 예시: \"고양이가 잠을 잡니다\"와 \"고양이는 낮잠을 잡니다\" 비교\n",
    "        - 참조: \"고양이 가 잠 을 잡니다\"\n",
    "        - 생성: \"고양이 는 낮잠 을 잡니다\"\n",
    "        - LCS: \"고양이 을 잡니다\"\n",
    "        - Precision = 3/5 = 0.6\n",
    "        - Recall = 3/5 = 0.6\n",
    "        - F1 = 0.6\n",
    "\n",
    "- 각 메트릭은 정밀도(Precision), 재현율(Recall), F1-score로 표현\n",
    "- ROUGE-1은 개별 단어 일치를, ROUGE-2는 문장 구조를, ROUGE-L은 전체적인 의미 유사성을 중점적으로 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e7aa557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE 점수: {'rouge1': 0.36923076923076925, 'rouge2': 0.21875000000000003, 'rougeL': 0.3538461538461538}\n"
     ]
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "from kiwipiepy import Kiwi\n",
    "\n",
    "# Kiwi 토크나이저 사용하여 토큰화하는 클래스 정의 \n",
    "class CustomKiwiTokenizer(Kiwi):\n",
    "    def tokenize(self, text):\n",
    "        return [t.form for t in super().tokenize(text)]\n",
    "\n",
    "# ROUGE 점수 계산 함수 정의\n",
    "def calculate_rouge_score(reference, candidate):\n",
    "    scorer = rouge_scorer.RougeScorer(\n",
    "        ['rouge1', 'rouge2', 'rougeL'], \n",
    "        tokenizer=CustomKiwiTokenizer()    # 한국어 형태소 분석기 사용\n",
    "    )\n",
    "    scores = scorer.score(reference, candidate)\n",
    "    return {\n",
    "        \"rouge1\": scores['rouge1'].fmeasure,\n",
    "        \"rouge2\": scores['rouge2'].fmeasure,\n",
    "        \"rougeL\": scores['rougeL'].fmeasure\n",
    "    }\n",
    "\n",
    "# ROUGE 점수 계산\n",
    "rouge_scores = calculate_rouge_score(text, summary)\n",
    "\n",
    "print(f\"ROUGE 점수: {rouge_scores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4b90f5",
   "metadata": {},
   "source": [
    "`(3) LLM-as-Judge`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2118d40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평가 결과: summary_score=8 summary_feedback='요약은 LangChain의 주요 기능과 목적을 잘 담고 있습니다. 특히 LLM 기반 애플리케이션 개발, 데이터 연결, 프롬프트 관리, 체인 구성, 메모리 기능 지원을 명확히 언급하여 핵심 내용을 잘 전달하고 있습니다. 다만, 에이전트 개발과 다양한 도구와의 통합 지원 부분이 빠져 있어 완전한 요약으로 보기는 어렵습니다. 이 부분을 포함하면 더 완성도 높은 요약이 될 것입니다.'\n",
      "점수: 8\n",
      "피드백: 요약은 LangChain의 주요 기능과 목적을 잘 담고 있습니다. 특히 LLM 기반 애플리케이션 개발, 데이터 연결, 프롬프트 관리, 체인 구성, 메모리 기능 지원을 명확히 언급하여 핵심 내용을 잘 전달하고 있습니다. 다만, 에이전트 개발과 다양한 도구와의 통합 지원 부분이 빠져 있어 완전한 요약으로 보기는 어렵습니다. 이 부분을 포함하면 더 완성도 높은 요약이 될 것입니다.\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# LLM 초기화\n",
    "llm = init_chat_model(\"openai:gpt-4.1-mini\", temperature=0)\n",
    "\n",
    "# 평가를 위한 Pydantic 모델\n",
    "class SummaryEvaluationResult(BaseModel):\n",
    "    \"\"\"요약 결과 평가\"\"\"\n",
    "    summary_score: int = Field(description=\"요약의 품질 점수 (1-10)\")\n",
    "    summary_feedback: str = Field(description=\"요약에 대한 피드백\")\n",
    "\n",
    "# 평가 프롬프트 템플릿 정의\n",
    "summary_evaluation_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"다음의 원본 텍스트, 요약 결과를 평가하세요. \n",
    "    요약이 원본 텍스트의 핵심 내용을 얼마나 잘 담고 있는지 평가하고 \n",
    "    1-10점 척도로 점수를 매기세요. 평가에 대한 피드백도 제공하세요.\"\"\"),\n",
    "    (\"human\", \"\"\"\n",
    "    원본 텍스트: {original_text}\n",
    "    \n",
    "    요약: {summary}\n",
    "    \"\"\")\n",
    "])\n",
    "\n",
    "# 구조화된 출력을 위한 LLM 설정\n",
    "summary_evaluation_llm = llm.with_structured_output(SummaryEvaluationResult)\n",
    "\n",
    "# 평가 체인 생성\n",
    "summary_evaluation_chain = summary_evaluation_prompt | summary_evaluation_llm\n",
    "\n",
    "# 평가 체인 실행\n",
    "evaluation_result = summary_evaluation_chain.invoke({\n",
    "    \"original_text\": text,\n",
    "    \"summary\": summary\n",
    "})\n",
    "print(\"평가 결과:\", evaluation_result)\n",
    "print(\"점수:\", evaluation_result.summary_score)\n",
    "print(\"피드백:\", evaluation_result.summary_feedback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a0da19",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### **[실습]**\n",
    "\n",
    "- 프롬프트를 수정하여 요약 체인을 정의합니다. \n",
    "- 뉴스 데이터를 사용하여 요약을 생성합니다. \n",
    "- 요약 결과를 평가합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f314c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 코드를 작성하세요. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612db70f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2. **키워드 추출 (Extraction)**\n",
    "\n",
    "- **키워드 추출**은 문서에서 가장 중요한 용어와 개념을 식별하는 과정임\n",
    "- 키워드 추출을 통해 문서의 **핵심 주제와 내용**을 빠르게 파악할 수 있음\n",
    "- 추출된 키워드는 문서 **분류, 검색, 인덱싱**에 활용됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7f7219",
   "metadata": {},
   "source": [
    "##### **1) 키워드 추출 체인**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "382b68e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "키워드 추출 결과: ['LangChain', '대규모 언어 모델(LLM)', '프레임워크']\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import init_chat_model\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "# LLM 초기화\n",
    "llm = init_chat_model(\"openai:gpt-4.1-mini\", temperature=0)\n",
    "\n",
    "# 키워드 추출을 위한 Pydantic 모델\n",
    "class Keywords(BaseModel):\n",
    "    \"\"\"텍스트에서 추출된 키워드 목록\"\"\"\n",
    "    keywords: List[str] = Field(description=\"텍스트에서 추출된 중요 키워드 목록 \")\n",
    "\n",
    "# 키워드 추출 프롬프트 템플릿 정의\n",
    "keyword_extraction_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"다음 텍스트에서 중요한 키워드를 추출하세요. 키워드는 텍스트의 핵심 주제와 개념을 나타내야 합니다. (최대 3개)\"),\n",
    "    (\"human\", \"{text}\")\n",
    "])\n",
    "\n",
    "# 구조화된 출력을 위한 LLM 설정\n",
    "keyword_extraction_llm = llm.with_structured_output(Keywords)\n",
    "\n",
    "# 키워드 추출 체인 생성\n",
    "keyword_extraction_chain = keyword_extraction_prompt | keyword_extraction_llm\n",
    "\n",
    "# 예시 사용\n",
    "keywords_result = keyword_extraction_chain.invoke({\"text\": text})\n",
    "print(\"키워드 추출 결과:\", keywords_result.keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615535bb",
   "metadata": {},
   "source": [
    "##### **2) 키워드 추출 평가**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee531a7",
   "metadata": {},
   "source": [
    "`(1) 키워드 개수`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbc89cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "답변: ['LangChain', '대규모 언어 모델(LLM)', '프레임워크']\n",
      "키워드 개수 평가 결과: {'score': True, 'count': 3}\n"
     ]
    }
   ],
   "source": [
    "# 평가도구 정의 \n",
    "def evaluate_keyword_count(keywords, min_count=1, max_count=3):\n",
    "    \"\"\"키워드 개수를 평가하는 함수\"\"\"\n",
    "    count = len(keywords)\n",
    "    return {\n",
    "        \"score\": min_count <= count <= max_count,\n",
    "        \"count\": count\n",
    "    }\n",
    "\n",
    "# 평가 수행\n",
    "print(f\"답변: {keywords_result.keywords}\")\n",
    "\n",
    "# 키워드 개수 평가\n",
    "result = evaluate_keyword_count(keywords_result.keywords)\n",
    "print(f\"키워드 개수 평가 결과: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e28911",
   "metadata": {},
   "source": [
    "`(2) LLM-as-Judge`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4bc64cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평가 결과: keyword_score=7 keyword_feedback='키워드가 LangChain과 대규모 언어 모델(LLM), 프레임워크라는 핵심 개념을 잘 포함하고 있어 기본적인 내용을 잘 반영하고 있습니다. 다만, 프롬프트 관리, 체인 구성, 에이전트 개발, 메모리 기능, 외부 데이터 소스 연결 등 LangChain의 구체적인 기능과 특징들이 키워드에 포함되지 않아 내용의 깊이나 다양성을 충분히 담아내지 못했습니다. 좀 더 상세한 기능이나 특징을 키워드에 추가하면 원본 텍스트의 핵심 내용을 더 잘 반영할 수 있을 것입니다.'\n",
      "점수: 7\n",
      "피드백: 키워드가 LangChain과 대규모 언어 모델(LLM), 프레임워크라는 핵심 개념을 잘 포함하고 있어 기본적인 내용을 잘 반영하고 있습니다. 다만, 프롬프트 관리, 체인 구성, 에이전트 개발, 메모리 기능, 외부 데이터 소스 연결 등 LangChain의 구체적인 기능과 특징들이 키워드에 포함되지 않아 내용의 깊이나 다양성을 충분히 담아내지 못했습니다. 좀 더 상세한 기능이나 특징을 키워드에 추가하면 원본 텍스트의 핵심 내용을 더 잘 반영할 수 있을 것입니다.\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# LLM 초기화\n",
    "llm = init_chat_model(\"openai:gpt-4.1-mini\", temperature=0)\n",
    "\n",
    "# 평가를 위한 Pydantic 모델\n",
    "class KeywordEvaluationResult(BaseModel):\n",
    "    \"\"\"키워드 추출 결과 평가\"\"\"\n",
    "    keyword_score: int = Field(description=\"키워드의 품질 점수 (1-10)\")\n",
    "    keyword_feedback: str = Field(description=\"키워드에 대한 피드백\")\n",
    "\n",
    "# 평가 프롬프트 템플릿 정의\n",
    "keyword_evaluation_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"다음의 원본 텍스트, 키워드 추출 결과를 평가하세요. \n",
    "    키워드가 원본 텍스트의 핵심 내용을 얼마나 잘 담고 있는지 평가하고 \n",
    "    1-10점 척도로 점수를 매기세요. 평가에 대한 피드백도 제공하세요.\"\"\"),\n",
    "    (\"human\", \"\"\"\n",
    "    원본 텍스트: {original_text}\n",
    "\n",
    "    키워드: {keywords}\n",
    "    \"\"\")\n",
    "])\n",
    "\n",
    "# 구조화된 출력을 위한 LLM 설정\n",
    "keyword_evaluation_llm = llm.with_structured_output(KeywordEvaluationResult)\n",
    "\n",
    "# 평가 체인 생성\n",
    "keyword_evaluation_chain = keyword_evaluation_prompt | keyword_evaluation_llm\n",
    "\n",
    "# 평가 체인 실행\n",
    "evaluation_result = keyword_evaluation_chain.invoke({\n",
    "    \"original_text\": text,\n",
    "    \"keywords\": keywords_result.keywords\n",
    "})\n",
    "\n",
    "print(\"평가 결과:\", evaluation_result)\n",
    "print(\"점수:\", evaluation_result.keyword_score)\n",
    "print(\"피드백:\", evaluation_result.keyword_feedback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c78ddba",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### **[실습]**\n",
    "\n",
    "- 프롬프트를 수정하여 키워드 추출 체인을 정의합니다. \n",
    "- 뉴스 데이터를 사용하여 키워드 추출 작업을 수행합니다. \n",
    "- 추출 결과를 평가합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d44dd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 코드를 작성하세요. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
